{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from nepalikit.tokenization import Tokenizer\n",
    "from nepalikit.preprocessing import TextProcessor\n",
    "from nepalikit.manage_stopwords import load_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.5):\n",
    "        super(CustomLSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        pooled_output = torch.mean(lstm_out, dim=1)\n",
    "        dropped_out = self.dropout(pooled_output)\n",
    "        return self.fc(dropped_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/pranjal/Downloads/fuse_project/tokenizer_vocab.json', 'r', encoding='utf-8') as vocab_file:\n",
    "    vocab = json.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "class CustomTokenizer:\n",
    "    def __init__(self, tokenizer, vocab=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab if vocab else {}\n",
    "\n",
    "    def build_vocab(self, texts):\n",
    "        index = 2\n",
    "        self.vocab['<PAD>'] = 0\n",
    "        self.vocab['<UNK>'] = 1\n",
    "        for text in texts:\n",
    "            tokens = self.tokenizer.tokenize(text, level = 'word')\n",
    "            for token in tokens:\n",
    "                if token not in self.vocab:\n",
    "                    self.vocab[token] = index\n",
    "                    index += 1\n",
    "\n",
    "    def encode(self, text, max_length):\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        token_ids = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n",
    "        token_ids = token_ids[:max_length] + [self.vocab['<PAD>']] * (max_length - len(token_ids))\n",
    "        return token_ids\n",
    "    \n",
    "custom_tokenizer = CustomTokenizer(tokenizer, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "vocab_size = 31159\n",
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomLSTMClassifier(vocab_size=vocab_size, embedding_dim=25, hidden_dim=8, output_dim=num_classes)\n",
    "model.load_state_dict(torch.load('/home/pranjal/Downloads/fuse_project/nepali_text_classification_model.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class_names = ['Education', 'ID', 'Policy', 'Press_Release']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TextProcessor()\n",
    "\n",
    "stopwords_path = '/home/pranjal/Downloads/fuse_project/NepaliStopWords'\n",
    "stopwords = load_stopwords(stopwords_path)\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = processor.remove_html_tags(text)\n",
    "    text = processor.remove_special_characters(text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub(r'[\\d०१२३४५६७८९]', '', text)\n",
    "    text = re.sub(r'\\b[a-zA-Z]+\\b', '', text)\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    filtered_words = [word for word in filtered_words if len(word) > 2]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Press_Release\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict(text, tokenizer, model, max_length, device):\n",
    "    text = preprocess_text(text)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_input = tokenizer.encode(text, max_length)\n",
    "        input_ids = torch.tensor(encoded_input, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        attention_mask = (input_ids != tokenizer.vocab['<PAD>']).long().to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        _, predicted_class = torch.max(outputs, 1)\n",
    "\n",
    "        return predicted_class.item()\n",
    "\n",
    "# sample_text = \"बल्खु त्रिभुवन विश्वविद्यालय विज्ञान प्रविधि अध्ययन संस्थान डीनको कार्यालय परीक्षा शाखा वल्खुद्वारा सेमेष्टर परीक्षा प्रणाली साल चैत्र महिनामा संचालन वर्षे स्नातक कम्प्यूटर विज्ञान सुचना प्रविधि विषय वर्ष शत्र समूहको नियमित शकत्रको अगाडिका समूहको आंशिक परीक्षाको परीक्षाफल विज्ञान प्रविधि अध्ययन संस्थान परीक्षा संचालक समितिको निर्णयानुसार प्रकाशित गरिएको परीक्षामा निम्नाकित कमांक परीक्षार्थीहरु उत्तीर्ण वर्षे स्नातक कम्प्यूटर विज्ञान सूचना प्रविधि वर्ष शत्र\"\n",
    "sample_text = \"ग्र्ट उपनियम वमोजिम जम्मा रकम सम्वन्धित ठेकेदार आपूर्तिकर्ताले बुझाउनु करमा मिलान पाउनेछ कारोबार गराउनु विशेष व्यक्तिको वार्षिक कारोबार वस्तु ढुवानी साधन भाडा ढुवानी सेवाको हकमा पतच्रास रुपैयाँसम्म बस्तु सेवा भएमा खुलाइ अनुसूची बमोजिमको ढाँचामा कारोबार गर्नको सम्बन्धित अधिकृतसमक्ष दरखास्त दिनु पर्नेछ उपनियम बमोजिम अनुमान सक्रिने नभे रुपैयाँसम्म वस्तु सेवा मिश्रित कारोबार सेवा व्यवसायको हक्रमा वीस रुपैयाँ वमोजिमको ढाँचामा कारोतार गर्नको सम्बन्धित क्रर अधिकृत समक्ष दरखास्त दिनु पर्नेछ ऐनको दफा उपदफा व्रमोजिम गर्नुपर्ने वस्तु सेवाको पर्नेछ अधिकृतले निरीक्षण गर्दाका बखत कारोबार व्यक्तिसँग आटौं संशोधनद्वारा नवौं संशोधनद्वारा संशोधित\"\n",
    "predicted_label = predict(sample_text, custom_tokenizer, model, max_length, device)\n",
    "predicted_class_name = class_names[predicted_label]\n",
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
